#!/usr/bin/python3
# Generate the specializer's labels file.
#
# Copyright (c) 2019 Mit authors
#
# The package is distributed under the MIT/X11 License.
#
# THIS PROGRAM IS PROVIDED AS IS, WITH NO WARRANTY. USE IS AT THE USER’S
# RISK.

import sys, json, pickle, functools, heapq

from mit_core.vm_data import Instruction
from path import State, Path
from futures import Future


if len(sys.argv) != 3:
    print("Usage: gen-labels PREDICTOR-FILENAME LABELS-FILENAME", file=sys.stderr)
    sys.exit(1)
predictor_filename = sys.argv[1]
labels_filename = sys.argv[2]

by_opcode = {i.opcode: i for i in Instruction}
with open(predictor_filename, 'rb') as f:
    # [{opcode (str): (new_state, count)]
    predictor = [
        {
            by_opcode[int(opcode, 16)]: (obj['new_state'], obj['count'])
            for opcode, obj in state.items()
        }
        for state in json.loads(f.read().decode())
    ]


class Distribution:
    '''
    Represents a frequency distribution over predictor states.
    Typically this represents some hypothetical situation.
    `NULL_HYPOTHESIS` is a Distribution covering all situations.
    The frequency of `state`, written `self[state]`, may be interpreted as
    the estimated number of times the state is visited and the hypothesis is
    true.

     - total - the sum of the frequencies of all the states.
    '''
    def __init__(self, iterable):
        '''
         - iterable - iterable of (state (int), frequency (float)).
           If a `state` is repeated, its `frequency`s will be summed.
        '''
        self.total = 0.
        self.frequencies = {}
        for state, frequency in iterable:
            assert type(state) is int and 0 <= state < len(predictor)
            assert type(frequency) is float and 0. <= frequency
            if frequency > 0.:
                if state not in self.frequencies:
                    self.frequencies[state] = 0.
                self.frequencies[state] += frequency
                self.total += frequency

    def __repr__(self):
        return 'Distribution({} states, total={})'.format(
            len(self.frequencies),
            self.total,
        )

    def __getitem__(self, state):
        '''Returns the frequency of `state` under this Distribution.'''
        assert type(state) is int and 0 <= state < len(predictor)
        return self.frequencies.get(state, 0.0)

    def predict(self):
        '''
        Returns a dict from Instruction to Distribution. Each entry gives
        a possible next Instruction and the Distribution that would result.
        The `total`s of the distributions give a frequency distribution over
        the Instructions.
        '''
        successors = {instruction: [] for instruction in Instruction}
        for state, frequency in self.frequencies.items():
            for instruction, (new_state, count) in predictor[state].items():
                probability = count / NULL_HYPOTHESIS[state]
                successors[instruction].append(
                    (new_state, frequency * probability)
                )
        return {
            instruction: Distribution(x)
            for instruction, x in successors.items()
            if len(x) > 0
        }

NULL_HYPOTHESIS = Distribution(
    (state, float(sum(count for _, count in transitions.values())))
    for state, transitions in enumerate(predictor)
)


@functools.total_ordering
class QueueItem:
    '''
    A potentially interesting Path and its resulting Distribution.
    Compares by `distribution.total` (reversed).
    '''
    def __init__(self, path, distribution):
        self.path = path
        self.distribution = distribution

    def __le__(self, other):
        return self.distribution.total.__ge__(other.distribution.total)

    def __eq__(self, other):
        return self.distribution.total.__eq__(other.distribution.total)

    def __hash__(self):
        return self.distribution.total.__hash__()

    def successors(self):
        '''Yields slightly longer paths.'''
        # Check for repetition.
        if self.path.remove_repeating_part() != self.path:
            # This path won't become a state, because we'll loop instead.
            return
        # Add one instruction to the Path in all useful ways.
        predictions = self.distribution.predict()
        for instruction, new_distribution in predictions.items():
            if self.path.state.is_worthwhile(instruction):
                yield QueueItem(
                    self.path + (instruction,),
                    new_distribution,
                )


print("Finding paths")

NUM_PATHS = 1100

# The `NUM_PATHS` most common instruction sequences.
# Path -> frequency
language = {}

heap = [QueueItem(Path(()), NULL_HYPOTHESIS)]
for _ in range(NUM_PATHS):
    try:
        item = heapq.heappop(heap)
    except IndexError:
        break
    language[item.path] = item.distribution
    for new_item in item.successors():
        heapq.heappush(heap, new_item)

# Sanity check.

for path in language:
    assert path[:-1] in language

# For each path, find strings of instructions that might come next.

print("Choosing multi-guesses")

# The set of Instructions that might modify the I register.
# We cannot guess beyond such an instruction.
GUESS_LIMITING = frozenset([
    Instruction.NEXT,
    Instruction.BRANCH,
    Instruction.BRANCHZ,
    Instruction.CALL,
])

def elaborate_future(distribution, state, total):
    '''
    Returns a Future representing the Instructions predicted by
    `distribution`.
     - distribution - Distribution.
     - state - State.
     - total - the frequency of the root of the decision tree. This is used
       to decide how deeply to elaborate the tree.
    '''
    children = {}
    for instruction, new_distribution in distribution.predict().items():
        if not state.is_worthwhile(instruction):
            # Useless guess: we cannot optimize it.
            pass
        elif distribution.total + new_distribution.total < total:
            # Useless guess: insufficiently probable.
            pass
        elif instruction in GUESS_LIMITING:
            # Do not guess beyond this one.
            children[instruction] = Future(new_distribution.total, {})
        else:
            # Recurse.
            children[instruction] = elaborate_future(
                new_distribution,
                state.step(state.specialize_instruction(instruction)),
                total,
            )
    return Future(distribution.total, children)

# Path -> non-empty tuple of Instruction
path_guesses = {path: [] for path in language}

for path, distribution in language.items():
    future = elaborate_future(distribution, path.state, distribution.total)
    while True:
        guess = tuple(future.guess())
        if len(guess) == 0:
            break
        if path + guess not in language:
            break
        path_guesses[path].append(guess)
        future.eliminate(guess)

# Generate state space of (path × rejects) with flood fill.

print("Generating control flow graph")

states = [] # List of (Path, rejects)
state_index = {} # Inverse of `states`.

# For each state in `states`, there is a transition in `transitions`.
# It can be:
#  - None - goto fallback;
#  - int g - goto g;
#  - (tuple(Instruction) guess, int c, int w) -
#    if (next==guess) { execute guess; goto c; } else goto w;
transitions = []

def enqueue(path, rejects):
    '''
    Adds a state if it has not been seen before.
     - path - Path.
     - rejects - frozenset of tuples of Instructions.
    '''
    assert isinstance(path, Path)
    assert isinstance(rejects, frozenset)
    state = (path, rejects)
    if state not in state_index:
        state_index[state] = len(state_index)
        states.append(state)
    return state_index[state]

assert enqueue(Path(()), frozenset()) == 0 # Root state.

# The work queue is the suffix of `states` that does not yet have transitions.
while len(transitions) < len(states):
    path, rejects = states[len(transitions)]
    for guess in path_guesses[path]:
        if all(guess[:l+1] not in rejects for l in range(len(guess))):
            # We have a guess.
            successor = (path + guess).remove_repeating_part()
            transitions.append((
                guess,
                enqueue(successor, frozenset()),
                enqueue(path, rejects.union([guess])),
            ))
            break
    else:
        # There is no good guess. Try again with a suffix of `path`.
        for path in path.suffixes():
            if path in language:
                transitions.append(enqueue(path, rejects))
                break
        else:
            # No more suffixes. Use the fallback executor.
            transitions.append(None)

assert len(states) == len(state_index) == len(transitions)

# Tension branches.

print("Tensioning branches")

# We only need labels for the states in which we make a guess.
label_map = {} # state -> label
for state, transition in enumerate(transitions):
    if isinstance(transition, tuple):
        label_map[state] = len(label_map)

def short_circuit(state):
    # Follows gotos, and maps `state` to a label or `None`.
    while isinstance(transitions[state], int):
        state = transitions[state]
    return label_map.get(state)

# List of (path properties... , guess, label or None, label or None).
labels = [
    (
        path.state.tos_constant,
        path.cached_depth(),
        path.checked_depth(),
        ' '.join(instruction.name for instruction in guess),
        short_circuit(c),
        short_circuit(w),
    )
    for (path, _), t in zip(states, transitions)
    if isinstance(t, tuple)
    for (guess, c, w) in [t]
]

assert len(label_map) == len(labels)

# Dump to a file.

with open(labels_filename, 'wb') as f:
    # [(
    #     tos_constant (int?),
    #     cached_depth (int),
    #     checked_depth (int),
    #     instruction_sequence (str, space-separated),
    #     if_correct (int?),
    #     if_wrong (int?)
    # )]
    pickle.dump(labels, file=f)
print('Wrote {}'.format(labels_filename))
