#!/usr/bin/python3
# Generate the specializer's predictor file.
#
# Copyright (c) 2019 Mit authors
#
# The package is distributed under the MIT/X11 License.
#
# THIS PROGRAM IS PROVIDED AS IS, WITH NO WARRANTY. USE IS AT THE USERâ€™S
# RISK.

import sys, pickle, hashlib, gzip

from mit_core.vm_data import Instruction


if len(sys.argv) != 3:
    print("Usage: gen-predictor TRACE-FILE PREDICTOR-FILE", file=sys.stderr)
    sys.exit(1)
trace_filename = sys.argv[1]
predictor_filename = sys.argv[2]

# Index the instruction set.

# bytes -> Instruction
TRACE_OPCODES = {
    i.opcode: i
    for i in Instruction
}

HISTORY_BITS = 20
SPARSITY = 3

class StepFunction:
    '''
    A callable that updates the history to record that an instruction was
    executed.
    '''
    def __init__(self, opcode):
        '''
         - opcode - int - the information about the instruction that will
           affect the history.
        '''
        seed = opcode
        def random():
            # Generate a random HISTORY_BITS-bit integer.
            nonlocal seed
            # These odd 64-bit constants come from the digits of pi.
            seed ^= 0x98EC4E6C89452821
            seed *= 0x8A2E03707344A409
            seed &= (1 << 64) - 1
            return seed >> (64 - HISTORY_BITS)
        _ = random()
        self._or_mask = (1<<HISTORY_BITS)-1
        for _ in range(SPARSITY):
            mask = random()
            self._or_mask &= mask
        self._xor_mask = random()

    def __call__(self, history):
        return (history | self._or_mask) ^ self._xor_mask

# Instruction -> HistoryStep
STEP_FUNCTIONS = {
    i: StepFunction(opcode)
    for opcode, i in TRACE_OPCODES.items()
}

# Predictor.

class Predictor:
    '''
    Public fields:
     - predictions - a dict from history value (int) to a dict from
       Instruction to count (int).
    '''

    def __init__(self):
        self.predictions = {} # history (int) -> Instruction -> count (int).

    def record_instruction(self, history, instruction):
        '''
        Records that `instruction` occurred at `history`.
         - history - 63-bit hash of history.
         - instruction - An Instruction.
        '''
        if history not in self.predictions:
            self.predictions[history] = {}
        counts = self.predictions[history]
        if instruction not in counts:
            counts[instruction] = 0
        counts[instruction] += 1

    def instruction_count(self, history, instruction):
        if history not in self.predictions:
            return 0
        return self.predictions[history][instruction.name]

# Build a Predictor.

print("Building a predictor")

def open_trace(trace_filename):
    '''Yields Instructions.'''
    with gzip.open(trace_filename, 'rb') as trace:
        byte = trace.read(1)
        while byte:
            byte = byte[0]
            if byte in TRACE_OPCODES:
                yield TRACE_OPCODES[byte]
            else:
                raise ValueError("Undefined instruction")
            byte = trace.read(1)

predictor = Predictor()
history = 0
progress = 0
for instruction in open_trace(trace_filename):
    predictor.record_instruction(history, instruction)
    history = STEP_FUNCTIONS[instruction](history)
    progress += 1
    if progress >= 1000000:
        progress = 0
        print('.', end='', flush=True)
print()

# Dump to a file, abstracting history, and removing rare states.

all_histories = [
    history
    for history, counts in predictor.predictions.items()
    if sum(counts.values()) >= 100
]

history_index = {
    history: state
    for state, history in enumerate(all_histories)
}

state_table = [
    {
        instruction.name: (
            history_index[STEP_FUNCTIONS[instruction](history)],
            count,
        )
        for (instruction, count) in predictor.predictions[history].items()
        if STEP_FUNCTIONS[instruction](history) in history_index
        if count > 0
    }
    for history in all_histories
]

with open(predictor_filename, 'wb') as f:
    # [{instruction_name: (new_state, count)]
    pickle.dump(state_table, f)
print('Wrote {}'.format(predictor_filename))

# Analysis tools, in case you ran Python with "-i".

from math import log

def shrink(mask):
    '''
    Masks out some of the history bits of `predictor`.
    Returns {history: {Instruction: int}}.

     - mask - a bitmask. For example:
       `-1` keeps the entire history;
       `0` discards the entire history;
       `0xFFFF` keeps the bottom 16 bits of the history.
    '''
    p = {}
    for k, v in predictor.predictions.items():
        k &= mask
        if k not in p: p[k] = {}
        for i, count in v.items():
            if i not in p[k]: p[k][i] = 0
            p[k][i] += count
    return p

def histogram(p=predictor.predictions):
    '''
    Groups histories by the number of outgoing transitions. Counts the groups.
    Most histories should predict a unique instruction, i.e. should have only
    one outgoing transition.

     - p - {history: {Instruction: int}}.
    '''
    counts = {}
    for v in p.values():
        l = len(v)
        if l not in counts: counts[l] = 0
        counts[l] += 1
    return sorted(counts.items())

def entropy(counts):
    '''
    Computes the number of bits of uncertainty contributed by a predictor
    state.

     - counts - [int].
    '''
    return sum(counts) * log(sum(counts), 2) - sum(n * log(n, 2) for n in counts)

def predictor_entropy(p=predictor.predictions):
    '''
    Computes the total number of bits of uncertainty of all states of a
    predictor.

     - p - {history: {Instruction: int}}.
    '''
    return sum(entropy(v.values()) for v in p.values())

def print_shrink_effects():
    for b in [0, 1, 2, 4, 8, 12, 16, 20]:
        p = shrink((1<<b)-1)
        print("With {} history bits, we get {} states, and the trace compresses to {} bits".format(
            b,
            len(p),
            predictor_entropy(p),
        ))
